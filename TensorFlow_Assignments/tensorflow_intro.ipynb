{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCI 1470 Lab 02: Introduction to Tensorflow #\n",
    "\n",
    "In this lab, we will be introducing [Tensorflow](http://tensorflow.org/), a cutting-edge library for developing, and evaluating deep neural network models.\n",
    "\n",
    "Tensorflow is a relatively new library (a couple of years old), and the developers at Google just released version 1.3 a couple of weeks ago. For this class, **assume all labs and projects will utilize Tensorflow Version 1.3**. \n",
    "\n",
    "The next couple of cells walk through the Tensorflow installation process, with all the information necessary to get Tensorflow working on both the department machines, as well as your local computers.\n",
    "\n",
    "We then walk through how Tensorflow works, and some of the basic functionality. There will be 3 check-off questions that all require you and your partner to write code, for the purpose of gaining familiarity with the library and the API. \n",
    "\n",
    "**Make sure to get all 3 questions checked off by your TA to get credit for this lab!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Tensorflow ##\n",
    "\n",
    "##### If Using Local Machine #####\n",
    "\n",
    "Please follow the instructions at this webpage to install Tensorflow on your local machine: [https://www.tensorflow.org/install/](https://www.tensorflow.org/install/). \n",
    "\n",
    "If you run into any trouble (either during lab, or if installing at home later), please post on Piazza or come to Hours.\n",
    "\n",
    "##### If Using Department Machine (directly, or via ssh) #####\n",
    "\n",
    "All department machines can run Tensorflow through our cs147 virtual environment. To run Tensorflow, please run the following command (in your terminal):\n",
    "\n",
    "```bash\n",
    "source /course/cs1470/cs147-tf-cpu/bin/activate\n",
    "```\n",
    "\n",
    "The above command activates the Python Virtual Environment, meaning any subsequent invocation of python, or ipython will be able to access any libraries installed in the given environment. Virtual Environments are a nice tool for keeping your python installations organized and clean, and we highly recommend using them in this class (and beyond!).\n",
    "\n",
    "To get the virtual environment to load in IPython Notebook, you will need to run the following commands (after activating the cs147-tf-cpu environment):\n",
    "\n",
    "```bash\n",
    "pip install --user ipykernel\n",
    "python -m ipykernel install --user --name=cs147-tf-cpu\n",
    "```\n",
    "\n",
    "Then, enter/load an IPython Notebook, and change your kernel to cs147-tf-cpu using the kernel tab at the top."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkoff - Import Tensorflow ###\n",
    "\n",
    "Run the following python code, and have your Lab TA check you off if there are no errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow 101 - The Computation Graph ##\n",
    "\n",
    "Writing Tensorflow code is very different than writing regular Python code. This is because the bulk of the computation in Tensorflow is executed in a separate process, containing high performing C code. However, instead of directly writing everything in C, Tensorflow defines a Python API, for both building the C computations, and for reading and writing data from/to this separate process.\n",
    "\n",
    "Here are the things to keep in mind.\n",
    "\n",
    "The core of Tensorflow is the **Computation Graph**. Tensorflow starts and ends with this graph - every operation you define, every intermediate value you calculate lives here.\n",
    "    \n",
    "  + This graph consists of nodes and edges. Nodes are **Tensors**, or matrices of varying dimensions (i.e 3D, 4D, etc.). The edges are **Operations** that take one or more tensors, and produce a new, resulting Tensor after applying a given transformation (i.e. addition, subtraction, matrix multiplication, etc.)\n",
    "  + All of these Tensors and Operations exist in this separate, high performing process. That means you can't print/peek into the Tensors like you would in regular Python.\n",
    "  + This graph defines a \"flow\" of Tensors, starting from an input, resulting in a desired output. Hence the library's name, **Tensorflow**.\n",
    "  \n",
    "There are two steps to every Tensorflow program:\n",
    "\n",
    "  + Defining the graph: Use Python's Tensorflow API to set up the inputs, all the transformations, the operations to run, and the desired outputs to collect.\n",
    "  + Interacting with the graph: Feed inputs into the Computation Graph, and collect outputs, transforming normal Python objects into Tensors to be read by the Computation Graph.\n",
    "  \n",
    "We'll be talking about how to define the Computation Graph soon. However, the crucial thing to understand is this second point - how to feed data to the computation graph, and how to read outputs back.\n",
    "\n",
    "The device that allows us to communicate with the computation graph is the **Session.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Sessions - Portal to the Computation Graph ###\n",
    "\n",
    "All of your interaction with the Computation Graph will happen through a **Session** object. Sessions allow you to not only load Python objects into the Graph, but they also allow you to run arbitrary operations, and fetch the values of given Tensors.\n",
    "\n",
    "To better understand this, consider the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(), dtype=string)\n",
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define a Constant Tensor on the Computation Graph\n",
    "hello = tf.constant('Hello World!')\n",
    "\n",
    "# Print the Tensor - this is not a normal Python object - it's a Tensor!!!\n",
    "print hello\n",
    "\n",
    "# Create a Session\n",
    "session = tf.Session()\n",
    "\n",
    "# Run (Fetch) the given Tensor, and print it's value - this is a normal Python object (str)\n",
    "print session.run(hello)\n",
    "\n",
    "# Close the session\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sessions act a lot like files in Python. They need to be opened, via the special ```tf.Session()``` constructor, and assigned to a variable. Then, to read a Tensor value from a session, you need to call ```session.run(val)``` to evaluate the set of operations resulting in the given Tensor. You must then close the session, to end the interaction.\n",
    "\n",
    "You can also *feed* values into a Computation Graph, via **feed_dicts** (feed dictionaries). These dictionaries provide a mapping between special Tensor objects called placeholders, that denote inputs coming from normal Python, and actual raw python objects.\n",
    "\n",
    "An example is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", dtype=string)\n",
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "# Define a normal Python string\n",
    "hello = \"Hello World!\"\n",
    "\n",
    "# Define a Placeholder Tensor on the Computation Graph - note that you have to define the type of a placeholder!\n",
    "string_tensor = tf.placeholder(dtype=tf.string)\n",
    "\n",
    "# Print the String Tensor - See what it looks like!\n",
    "print string_tensor\n",
    "\n",
    "# Create a Session\n",
    "session = tf.Session()\n",
    "\n",
    "# Run (Fetch) the given placeholder, but after feeding in the value in `hello`\n",
    "print session.run(string_tensor, feed_dict={string_tensor: hello})\n",
    "\n",
    "# Close Session\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play around with the above example to make sure that everything makes sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkoff - Placeholders, Operations, and Sessions ###\n",
    "\n",
    "The following code block is incomplete. Using your knowledge of Placeholders, the Computation Graph, and Sessions, have the following code print \"Hello NAME!\" after reading your name from STDIN.\n",
    "\n",
    "Hint: You might want to look at the Tensorflow API/Stack Overflow for how to concatenate String Tensors.\n",
    "\n",
    "Fill out the code block, and have your Lab TA check you and your partner off after you succeed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your name here: Babak\n",
      "Hello Babak!\n"
     ]
    }
   ],
   "source": [
    "# Get your name from stdin\n",
    "name = raw_input(\"Enter your name here: \")\n",
    "\n",
    "# Define a Placeholder Tensor for your name\n",
    "name_tensor = tf.placeholder(dtype=tf.string)\n",
    "\n",
    "# Define a Constant Tensor\n",
    "hello_tensor = tf.constant(\"Hello \")\n",
    "exclamation_tensor = tf.constant(\"!\")\n",
    "\n",
    "# OPERATIONS GO HERE\n",
    "hello_name_tensor = hello_tensor + name_tensor + exclamation_tensor\n",
    "\n",
    "# Create a Session\n",
    "session = tf.Session()\n",
    "\n",
    "# SESSION LOGIC GOES HERE\n",
    "hello_name = session.run(hello_name_tensor,feed_dict={name_tensor:name})\n",
    "print hello_name\n",
    "\n",
    "# Close Session\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all Together - Placeholder Shapes, Variables, and Neural Networks ###\n",
    "\n",
    "There are two other big things to understand about Tensorflow. The first is related to Placeholders, like we've seen before. Whereas in the above examples, we only define our placeholders with a dtype (the type of input it will hold), placeholders usually are also defined by their *shape*, or matrix dimensions (like in Numpy). \n",
    "\n",
    "Consider the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_placeholder = tf.placeholder(dtype=tf.float32, shape=[784])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we define a placeholder of type float32, with a shape (dimension) of 784. In other words, our mnist_placeholder stores float vectors with 784 elements (hmm, seems awfully familiar)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other big thing in Tensorflow are **Variables.** Like we've seen in class, neural networks are defined by a set of parameters, that we learn during the training process. These parameters are **Variables** that are special types of Tensors that are slightly different than the placeholders, or the constants we've looked at before. \n",
    "\n",
    "Furthermore, Variables are defined with a special syntax, and must be initialized (via a call to session.run) first, before any other evaluation.\n",
    "\n",
    "To make this more clear, consider the following Variables (these should look very familiar, from your first homework)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(784, 10) dtype=float32_ref>\n",
      "<tf.Variable 'Variable_1:0' shape=(10,) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "# Create Variable for MNIST Classifier Weight - initialize Variable to be zero matrix, of shape [784, 10]\n",
    "W = tf.Variable(initial_value=tf.zeros(shape=[784, 10]))\n",
    "print W\n",
    "\n",
    "# Create Variable for MNIST Classifier Bias - initialize Variable ot be zero vector with 10 elements\n",
    "b = tf.Variable(initial_value=tf.zeros(shape=[10]))\n",
    "print b\n",
    "\n",
    "# Create Session\n",
    "session = tf.Session()\n",
    "\n",
    "# Initialize all Variables => Special call => REMEMBER THIS!\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "# Close Session\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkoff - MNIST Classifier in Tensorflow ###\n",
    "\n",
    "We now have all the pieces we need to start using Tensorflow effectively. First, start by reading and working through the Tensorflow MNIST Tutorial: https://www.tensorflow.org/get_started/mnist/beginners\n",
    "\n",
    "It has a lot of information we've already covered, and a lot of the code you'll need to become familiar with to start writing Neural Network Models in Tensorflow, including activation functions, matrix multiplication, and training via SGD. Note that in Tensorflow, all gradient calculations are taken care of for you.\n",
    "\n",
    "Read the tutorial, and feel free to run the provided code, to make sure you understand what's going on. After doing so, fill out the following code so that it performs identically to the code you wrote in the first homework assignment.\n",
    "\n",
    "Get checked off by your Lab TA to successfully complete Lab 02 - Tensorflow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/losses/losses_impl.py:691: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "Iteration 0\tLoss Value: 2.574\n",
      "Iteration 1000\tLoss Value: 0.000\n",
      "Iteration 2000\tLoss Value: 60.470\n",
      "Iteration 3000\tLoss Value: 0.000\n",
      "Iteration 4000\tLoss Value: 0.000\n",
      "Iteration 5000\tLoss Value: 0.000\n",
      "Iteration 6000\tLoss Value: 0.262\n",
      "Iteration 7000\tLoss Value: 0.000\n",
      "Iteration 8000\tLoss Value: 0.000\n",
      "Iteration 9000\tLoss Value: 0.000\n",
      "Test Accuracy: 0.845\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "\n",
    "# Read MNIST Dataset from TF Helper\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# Setup Parameters\n",
    "input_size, num_classes = 784, 10\n",
    "num_train_steps = 10000\n",
    "learning_rate = 0.5\n",
    "\n",
    "# Create Placeholders, Variables\n",
    "x_tensor = tf.placeholder(tf.float32, [1,784])     # Placeholder for Input Image => Single Vector, Dimension [1, 784]\n",
    "y_tensor = tf.placeholder(tf.float32, [1,10])     # Placeholder for Output Class => Vector, One-Hot, Dimension [1, 10]\n",
    "W = tf.Variable(tf.random_normal([784,10], stddev=.1),trainable=True)            # Weights\n",
    "b = tf.Variable(tf.random_normal([1,10], stddev=.1),trainable=True)            # Bias\n",
    "\n",
    "# Use operations to generate final logits (no softmax)\n",
    "logits = tf.matmul(x_tensor,W) + b\n",
    "\n",
    "# Get probabilities by using the softmax activation on the given logits\n",
    "probabilities = tf.nn.softmax(logits)\n",
    "\n",
    "# Compute Loss Value via TF Loss Helper\n",
    "loss = tf.losses.softmax_cross_entropy(onehot_labels=y_tensor, logits=logits)\n",
    "\n",
    "# Create Gradient Descent Optimizer, training operation for updating weights\n",
    "sgd = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "train_op = sgd.minimize(loss)\n",
    "\n",
    "# Create Session\n",
    "session = tf.Session()\n",
    "\n",
    "# Initialize all Variables\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "# Training Loop!\n",
    "for i in range(num_train_steps):\n",
    "    # Get next element from the MNIST Training Data\n",
    "    next_x, next_y = mnist.train.next_batch(1)\n",
    "    \n",
    "    # Collect/Run Loss, Training Operation via single call to session.run (note multiple fetches!)\n",
    "    l, _ = session.run([loss, train_op], feed_dict={x_tensor: next_x, y_tensor: next_y})\n",
    "    \n",
    "    # Print Loss every so often\n",
    "    if i % 1000 == 0:\n",
    "        print 'Iteration %d\\tLoss Value: %.3f' % (i, l)\n",
    "        \n",
    "# Evaluate Accuracy on Test Data\n",
    "correct, test_x, test_y = 0.0, mnist.test.images, mnist.test.labels\n",
    "for i in range(10000):\n",
    "    next_x, next_y = test_x[i], test_y[i]\n",
    "    p = session.run([probabilities], feed_dict={x_tensor: [next_x], y_tensor: [next_y]})\n",
    "    if np.argmax(p[0]) == np.argmax(next_y):\n",
    "        correct += 1\n",
    "print 'Test Accuracy: %.3f' % (correct / 10000.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
